name: Reliable Call Transcription (1000+ Recordings)

on:
  schedule:
    # Run every day at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      target_date:
        description: 'Date to process (YYYY-MM-DD). Leave empty for yesterday.'
        required: false
        type: string

# needed to upload the Excel to a Release
permissions:
  contents: write

jobs:
  transcribe-calls:
    runs-on: ubuntu-latest
    timeout-minutes: 300  # 5 hours

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        # add Excel libs
        pip install pandas openpyxl

    - name: Run reliable transcription
      env:
        RC_CLIENT_ID: ${{ secrets.RC_CLIENT_ID }}
        RC_CLIENT_SECRET: ${{ secrets.RC_CLIENT_SECRET }}
        RC_JWT: ${{ secrets.RC_JWT }}
        GROQ_API_KEY_1: ${{ secrets.GROQ_API_KEY_1 }}
        GROQ_API_KEY_2: ${{ secrets.GROQ_API_KEY_2 }}
        GROQ_API_KEY_3: ${{ secrets.GROQ_API_KEY_3 }}
        GROQ_API_KEY_4: ${{ secrets.GROQ_API_KEY_4 }}
        GROQ_API_KEY_5: ${{ secrets.GROQ_API_KEY_5 }}
        GROQ_API_KEY_6: ${{ secrets.GROQ_API_KEY_6 }}
        TARGET_DATE: ${{ inputs.target_date }}
        # Ultra-conservative settings to avoid RC limits
        RC_RPS: 0.25
        RC_MEDIA_DELAY: 12
      run: |
        python reliable_processor.py

    - name: Upload results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: transcription-results-${{ github.run_number }}
        path: daily_recordings/
        retention-days: 30

    - name: Show summary
      if: always()
      run: |
        echo "=== TRANSCRIPTION COMPLETE ==="
        if [ -d "daily_recordings" ]; then
          echo "Results saved in daily_recordings/"
          find daily_recordings -name "*.json" -exec echo "Found: {}" \;
          if [ -f daily_recordings/*/summary.json ]; then
            echo "=== SUMMARY ==="
            cat daily_recordings/*/summary.json
          fi
        fi

    # ========== NEW: Set DATE_STR for file/release ==========
    - name: Set DATE_STR
      run: |
        if [ -n "${{ inputs.target_date }}" ]; then
          DATE_STR="${{ inputs.target_date }}"
        else
          DATE_STR="$(date -u +%F)"   # e.g. 2025-08-25
        fi
        echo "DATE_STR=$DATE_STR" >> $GITHUB_ENV

    # ========== NEW: Build Excel from all CSV/JSON in daily_recordings ==========
    - name: Build Excel (CSV + JSON → data-${{ env.DATE_STR }}.xlsx)
      if: always()
      run: |
        python - << 'PY'
        import os, glob, json, re
        import pandas as pd

        base = "daily_recordings"
        out = f"data-${{ os.environ['DATE_STR'] }}.xlsx"

        if not os.path.isdir(base):
            print("No daily_recordings/ directory found; creating empty Excel.")
            with pd.ExcelWriter(out, engine="openpyxl") as w:
                pd.DataFrame([]).to_excel(w, index=False, sheet_name="EMPTY")
            raise SystemExit(0)

        def clean_sheet(name: str) -> str:
            # Excel restrictions: <=31 chars, no []:*?/\
            name = re.sub(r'[\[\]\:\*\?\/\\]', '_', name)[:31] or "Sheet"
            return name

        csvs  = sorted(glob.glob(os.path.join(base, "**", "*.csv"),  recursive=True))
        jsons = sorted(glob.glob(os.path.join(base, "**", "*.json"), recursive=True))

        used = set()
        def uniq(n: str) -> str:
            base = n[:28]
            i, s = 1, n
            while s in used:
                s = f"{base}_{i}"
                i += 1
            used.add(s)
            return s

        with pd.ExcelWriter(out, engine="openpyxl") as w:
            for p in csvs:
                try:
                    df = pd.read_csv(p)
                except Exception as e:
                    print(f"CSV read failed {p}: {e}")
                    continue
                sheet = uniq(clean_sheet(os.path.splitext(os.path.basename(p))[0] or "CSV"))
                df.to_excel(w, index=False, sheet_name=sheet)

            for p in jsons:
                try:
                    with open(p, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    try:
                        df = pd.json_normalize(data)
                    except Exception:
                        df = pd.DataFrame({"raw_json":[json.dumps(data, ensure_ascii=False)]})
                except Exception as e:
                    print(f"JSON read failed {p}: {e}")
                    continue
                sheet = uniq(clean_sheet(os.path.splitext(os.path.basename(p))[0] or "JSON"))
                df.to_excel(w, index=False, sheet_name=sheet)

        print(f"Wrote {out} with {len(csvs)} CSV sheet(s) and {len(jsons)} JSON sheet(s).")
        PY

    # ========== NEW: Publish the Excel on a GitHub Release ==========
    - name: Publish Excel on Release
      if: always()
      uses: softprops/action-gh-release@v2
      with:
        tag_name: excel-${{ env.DATE_STR }}
        name: "Daily Excel — ${{ env.DATE_STR }}"
        files: data-${{ env.DATE_STR }}.xlsx
